#!/usr/bin/env python3
"""
Teste Completo e Robusto do Modelo Super Sete
=============================================
Testa o modelo atual com valida√ß√µes espec√≠ficas para loterias
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from src.core.common_interface import SuperSeteInterface, create_analyzer, quick_analysis, quick_validation
from src.validation.validator import SuperSeteValidator, SuperSeteValidationConfig
import json
import pandas as pd
import numpy as np
import os
from datetime import datetime
from typing import Dict, List, Any

class SuperSeteTester:
    """Classe para testes completos do modelo Super Sete"""
    
    def __init__(self, config_name: str = 'longo', n_concursos: int = 1000):
        self.interface = create_analyzer(config_name, n_concursos)
        self.config_name = config_name
        self.n_concursos = n_concursos
        self.results = {}
        
    def test_basic_functionality(self) -> Dict[str, Any]:
        """Testa funcionalidade b√°sica do modelo"""
        print("üß™ TESTE 1: FUNCIONALIDADE B√ÅSICA")
        print("="*50)
        
        try:
            # Carregar dados
            df = self.interface.load_data("data/raw/Super Sete.xlsx")
            print(f"‚úÖ Dados carregados: {len(df)} concursos")
            
            # Verificar estrutura dos dados
            colunas_numericas = [col for col in df.columns if col.startswith('Coluna_')]
            print(f"‚úÖ Colunas num√©ricas encontradas: {len(colunas_numericas)}")
            
            # Testar gera√ß√£o de jogos usando m√©todos corretos
            # Simular probabilidades para teste
            prob_by_col = {}
            for col in colunas_numericas:
                prob_by_col[col] = np.ones(10) / 10
            
            jogos_amostragem = self.interface.analyzer.sample_games(prob_by_col, n_games=5)
            jogos_ranking = self.interface.analyzer.top_product_games(prob_by_col, n_games=5, top_per_col=5)
            
            print(f"‚úÖ Jogos gerados (ranking): {len(jogos_ranking)}")
            print(f"‚úÖ Jogos gerados (amostragem): {len(jogos_amostragem)}")
            
            # Verificar validade dos jogos
            jogos_validos = self._validate_games(jogos_ranking + jogos_amostragem)
            print(f"‚úÖ Jogos v√°lidos: {jogos_validos}/{len(jogos_ranking + jogos_amostragem)}")
            
            return {
                'status': 'success',
                'concursos': len(df),
                'colunas': len(colunas_numericas),
                'jogos_ranking': len(jogos_ranking),
                'jogos_amostragem': len(jogos_amostragem),
                'jogos_validos': jogos_validos,
                'total_jogos': len(jogos_ranking + jogos_amostragem)
            }
            
        except Exception as e:
            print(f"‚ùå Erro no teste b√°sico: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def test_model_performance(self) -> Dict[str, Any]:
        """Testa performance do modelo usando diretamente o SuperSeteAnalyzer"""
        print("\nüìä TESTE 2: PERFORMANCE DO MODELO")
        print("="*50)
        
        try:
            # Executar an√°lise completa usando diretamente o analisador
            resultados = self.interface.analyzer.run_analysis(
                excel_path="data/raw/Super Sete.xlsx",
                n_jogos=10,
                topk=5,
                seed=42,
                use_cache=True,
                save_results=False  # N√£o salvar para teste
            )
            
            # Analisar m√©tricas
            confianca_media = resultados.get('avg_confidence', 0)
            colunas_previsiveis = resultados.get('predictable_cols', 0)
            
            print(f"üéØ Confian√ßa m√©dia: {confianca_media:.3f}")
            print(f"üìà Colunas previs√≠veis: {colunas_previsiveis}")
            
            # Testar gera√ß√£o de jogos usando m√©todos corretos do Super Sete
            # Primeiro precisamos obter as probabilidades das colunas
            df = self.interface.load_data("data/raw/Super Sete.xlsx")
            numeric_cols = [col for col in df.columns if col.startswith('Coluna_')]
            
            # Simular probabilidades para teste (em um caso real, viria da an√°lise)
            prob_by_col = {}
            for col in numeric_cols:
                # Distribui√ß√£o uniforme para teste
                prob_by_col[col] = np.ones(10) / 10
            
            # Usar m√©todos corretos do SuperSeteAnalyzer
            jogos_amostragem = self.interface.analyzer.sample_games(prob_by_col, n_games=5)
            jogos_ranking = self.interface.analyzer.top_product_games(prob_by_col, n_games=5, top_per_col=5)
            
            # Para jogos de alta confian√ßa, precisamos das confian√ßas tamb√©m
            confidence_by_col = {col: 0.8 for col in numeric_cols}  # Simular alta confian√ßa
            jogos_alta_confianca = self.interface.analyzer._generate_high_confidence_games(
                prob_by_col, confidence_by_col, n_jogos=5, topk=5
            )
            
            print(f"üéÆ Jogos ranking: {len(jogos_ranking)}")
            print(f"üéÆ Jogos amostragem: {len(jogos_amostragem)}")
            print(f"üéÆ Jogos alta confian√ßa: {len(jogos_alta_confianca)}")
            
            # Avaliar qualidade
            if confianca_media > 0.6:
                qualidade = "excelente"
            elif confianca_media > 0.4:
                qualidade = "boa"
            elif confianca_media > 0.2:
                qualidade = "moderada"
            else:
                qualidade = "baixa"
            
            print(f"‚≠ê Qualidade geral: {qualidade}")
            
            return {
                'status': 'success',
                'confianca_media': confianca_media,
                'colunas_previsiveis': colunas_previsiveis,
                'qualidade': qualidade,
                'jogos_gerados': {
                    'ranking': len(jogos_ranking),
                    'amostragem': len(jogos_amostragem),
                    'alta_confianca': len(jogos_alta_confianca)
                },
                'resultados_completos': resultados
            }
            
        except Exception as e:
            print(f"‚ùå Erro no teste de performance: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def test_validation_integration(self) -> Dict[str, Any]:
        """Testa integra√ß√£o com validator"""
        print("\nüîç TESTE 3: INTEGRA√á√ÉO COM VALIDATOR")
        print("="*50)
        
        try:
            # Configura√ß√£o de valida√ß√£o otimizada
            validation_config = {
                'test_size': 0.2,
                'cv_folds': 3,  # Menos folds para teste r√°pido
                'min_samples': 20,
                'confidence_level': 0.95,
                'save_plots': False,  # Desabilitar plots para teste
                'results_dir': "resultados_teste",
                'plot_dir': "resultados_teste/plots"
            }
            
            # Executar valida√ß√£o
            results = self.interface.validate_model("data/raw/Super Sete.xlsx", validation_config)
            
            # Analisar resultados da valida√ß√£o
            colunas_testadas = len([k for k in results.keys() if k.startswith('Coluna_') and 'error' not in results[k]])
            colunas_significativas = len([k for k, v in results.items() 
                                        if isinstance(v, dict) and v.get('is_significant', False)])
            
            print(f"‚úÖ Colunas testadas: {colunas_testadas}")
            print(f"‚úÖ Colunas significativas: {colunas_significativas}")
            
            if colunas_testadas > 0:
                taxa_sucesso = colunas_significativas / colunas_testadas * 100
                print(f"üìä Taxa de sucesso: {taxa_sucesso:.1f}%")
            else:
                taxa_sucesso = 0
            
            return {
                'status': 'success',
                'colunas_testadas': colunas_testadas,
                'colunas_significativas': colunas_significativas,
                'taxa_sucesso': taxa_sucesso,
                'resultados_validacao': results
            }
            
        except Exception as e:
            print(f"‚ùå Erro na integra√ß√£o com validator: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def test_data_quality(self) -> Dict[str, Any]:
        """Testa qualidade dos dados usando analisadores do Super Sete"""
        print("\nüîç TESTE 4: QUALIDADE DOS DADOS")
        print("="*50)
        
        try:
            df = self.interface.load_data("data/raw/Super Sete.xlsx")
            colunas_numericas = [col for col in df.columns if col.startswith('Coluna_')]
            
            qualidade_dados = {}
            analises_especializadas = {}
            
            for col in colunas_numericas:
                serie = df[col].dropna().values
                
                # An√°lise b√°sica
                valores_unicos = len(np.unique(serie))
                entropia = self._calculate_entropy(pd.Series(serie))
                
                # Verificar outliers
                q1, q3 = np.percentile(serie, [25, 75])
                iqr = q3 - q1
                outliers = len(serie[(serie < q1 - 1.5*iqr) | (serie > q3 + 1.5*iqr)])
                
                qualidade_dados[col] = {
                    'valores_unicos': valores_unicos,
                    'entropia': entropia,
                    'outliers': outliers,
                    'outliers_pct': outliers / len(serie) * 100 if len(serie) > 0 else 0
                }
                
                # Usar analisadores especializados do Super Sete
                try:
                    # An√°lise temporal - usar m√©todos corretos
                    seasonality = self.interface.temporal_analyzer.detect_seasonality(serie)
                    trend = self.interface.temporal_analyzer.calculate_trend(serie)
                    temporal_analysis = {
                        'seasonality': seasonality,
                        'trend': trend
                    }
                    analises_especializadas[f"{col}_temporal"] = temporal_analysis
                    
                    # An√°lise de entropia - usar m√©todos corretos
                    entropy_info = self.interface.entropy_analyzer.calculate_entropy(serie)
                    randomness = self.interface.entropy_analyzer.test_randomness(serie)
                    entropy_analysis = {
                        'entropy': entropy_info,
                        'randomness': randomness
                    }
                    analises_especializadas[f"{col}_entropy"] = entropy_analysis
                    
                    # An√°lise de confian√ßa - usar m√©todos corretos
                    # Simular predi√ß√µes para teste
                    predictions = np.random.random(10)  # Simular probabilidades
                    confidence_intervals = self.interface.confidence_analyzer.calculate_confidence_intervals(predictions)
                    confidence_analysis = {
                        'intervals': confidence_intervals
                    }
                    analises_especializadas[f"{col}_confidence"] = confidence_analysis
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro na an√°lise especializada de {col}: {e}")
                    analises_especializadas[f"{col}_error"] = str(e)
            
            print(f"‚úÖ An√°lise de qualidade conclu√≠da para {len(colunas_numericas)} colunas")
            print(f"‚úÖ An√°lises especializadas: {len(analises_especializadas)}")
            
            return {
                'status': 'success',
                'colunas_analisadas': len(colunas_numericas),
                'qualidade_detalhada': qualidade_dados,
                'analises_especializadas': analises_especializadas
            }
            
        except Exception as e:
            print(f"‚ùå Erro no teste de qualidade: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def test_supersete_integration(self) -> Dict[str, Any]:
        """Testa integra√ß√£o direta com fun√ß√µes do Super Sete"""
        print("\nüîó TESTE 5: INTEGRA√á√ÉO SUPER SETE")
        print("="*50)
        
        try:
            # Testar m√©todos diretos do SuperSeteAnalyzer
            analyzer = self.interface.analyzer
            
            # Testar carregamento de dados
            df = analyzer.load_data("data/raw/Super Sete.xlsx")
            print(f"‚úÖ Carregamento direto: {len(df)} concursos")
            
            # Testar an√°lise de coluna individual
            coluna_teste = df['Coluna_1'].values
            analise_coluna = analyzer.analyze_column(coluna_teste, 'Coluna_1')
            print(f"‚úÖ An√°lise de coluna: {len(analise_coluna)} m√©tricas")
            
            # Testar cria√ß√£o de features
            X, y, feature_names = analyzer.create_features(coluna_teste, window=10)
            print(f"‚úÖ Features criadas: {X.shape[0]} amostras, {X.shape[1]} features")
            
            # Testar analisadores especializados usando m√©todos corretos
            seasonality = analyzer.temporal_analyzer.detect_seasonality(coluna_teste)
            trend = analyzer.temporal_analyzer.calculate_trend(coluna_teste)
            temporal_result = {'seasonality': seasonality, 'trend': trend}
            
            entropy_info = analyzer.entropy_analyzer.calculate_entropy(coluna_teste)
            randomness = analyzer.entropy_analyzer.test_randomness(coluna_teste)
            entropy_result = {'entropy': entropy_info, 'randomness': randomness}
            
            # Para confian√ßa, simular predi√ß√µes
            predictions = np.random.random(10)
            confidence_intervals = analyzer.confidence_analyzer.calculate_confidence_intervals(predictions)
            confidence_result = {'intervals': confidence_intervals}
            
            print(f"‚úÖ An√°lise temporal: {len(temporal_result)} m√©tricas")
            print(f"‚úÖ An√°lise entropia: {len(entropy_result)} m√©tricas")
            print(f"‚úÖ An√°lise confian√ßa: {len(confidence_result)} m√©tricas")
            
            # Testar gera√ß√£o de jogos usando m√©todos corretos
            # Simular probabilidades para teste
            numeric_cols = [col for col in df.columns if col.startswith('Coluna_')]
            prob_by_col = {}
            for col in numeric_cols:
                prob_by_col[col] = np.ones(10) / 10
            
            jogos_amostragem = analyzer.sample_games(prob_by_col, n_games=3)
            jogos_ranking = analyzer.top_product_games(prob_by_col, n_games=3, top_per_col=5)
            
            print(f"‚úÖ Jogos amostragem: {len(jogos_amostragem)}")
            print(f"‚úÖ Jogos ranking: {len(jogos_ranking)}")
            
            return {
                'status': 'success',
                'concursos_carregados': len(df),
                'analise_coluna_metricas': len(analise_coluna),
                'features_criadas': X.shape[0] if len(X) > 0 else 0,
                'n_features': X.shape[1] if len(X) > 0 else 0,
                'temporal_metricas': len(temporal_result),
                'entropy_metricas': len(entropy_result),
                'confidence_metricas': len(confidence_result),
                'jogos_amostragem': len(jogos_amostragem),
                'jogos_ranking': len(jogos_ranking),
                'integracao_funcionando': True
            }
            
        except Exception as e:
            print(f"‚ùå Erro na integra√ß√£o Super Sete: {e}")
            return {'status': 'error', 'error': str(e), 'integracao_funcionando': False}
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """Executa teste completo"""
        print("üöÄ INICIANDO TESTE COMPLETO DO MODELO SUPER SETE")
        print("="*60)
        
        # Executar todos os testes
        test1 = self.test_basic_functionality()
        test2 = self.test_model_performance()
        test3 = self.test_validation_integration()
        test4 = self.test_data_quality()
        test5 = self.test_supersete_integration()  # Novo teste de integra√ß√£o
        
        # Compilar resultados
        resultados_completos = {
            'timestamp': datetime.now().isoformat(),
            'configuracao': {
                'config_name': self.config_name,
                'n_concursos': self.n_concursos
            },
            'testes': {
                'funcionalidade_basica': test1,
                'performance_modelo': test2,
                'integracao_validator': test3,
                'qualidade_dados': test4,
                'integracao_supersete': test5
            },
            'resumo': self._generate_summary(test1, test2, test3, test4, test5)
        }
        
        # Salvar resultados
        self._save_test_results(resultados_completos)
        
        return resultados_completos
    
    def _validate_games(self, jogos: List) -> int:
        """Valida se os jogos est√£o no formato correto"""
        validos = 0
        for jogo in jogos:
            # Aceitar tanto listas quanto tuplas
            if ((isinstance(jogo, (list, tuple))) and 
                len(jogo) == 7 and 
                all(isinstance(n, int) and 0 <= n <= 9 for n in jogo)):
                validos += 1
        return validos
    
    def _calculate_entropy(self, serie: pd.Series) -> float:
        """Calcula entropia de uma s√©rie"""
        try:
            from scipy.stats import entropy
            counts = serie.value_counts()
            return float(entropy(counts))
        except:
            return 0.0
    
    def _generate_summary(self, test1: Dict, test2: Dict, test3: Dict, test4: Dict, test5: Dict) -> Dict[str, Any]:
        """Gera resumo dos testes"""
        total_testes = 5
        testes_sucesso = sum(1 for test in [test1, test2, test3, test4, test5] if test.get('status') == 'success')
        
        # Verificar se a integra√ß√£o Super Sete est√° funcionando
        integracao_ok = test5.get('integracao_funcionando', False)
        
        return {
            'total_testes': total_testes,
            'testes_sucesso': testes_sucesso,
            'taxa_sucesso': testes_sucesso / total_testes * 100,
            'integracao_supersete_ok': integracao_ok,
            'status_geral': 'aprovado' if testes_sucesso >= 4 and integracao_ok else 'reprovado'
        }
    
    def _save_test_results(self, resultados: Dict[str, Any]) -> None:
        """Salva resultados do teste"""
        pasta_resultados = "resultados_teste"
        if not os.path.exists(pasta_resultados):
            os.makedirs(pasta_resultados)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        nome_arquivo = f"teste_completo_{timestamp}.json"
        caminho_arquivo = os.path.join(pasta_resultados, nome_arquivo)
        
        with open(caminho_arquivo, "w", encoding="utf-8") as f:
            json.dump(resultados, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nüíæ Resultados salvos em: {caminho_arquivo}")

def main():
    """Fun√ß√£o principal para executar testes"""
    print("üß™ TESTADOR COMPLETO SUPER SETE")
    print("="*50)
    
    # Criar testador
    tester = SuperSeteTester('longo', 1000)
    
    # Executar teste completo
    resultados = tester.run_comprehensive_test()
    
    # Mostrar resumo
    print("\n" + "="*60)
    print("üìã RESUMO DOS TESTES")
    print("="*60)
    
    resumo = resultados['resumo']
    print(f"‚úÖ Testes executados: {resumo['total_testes']}")
    print(f"‚úÖ Testes aprovados: {resumo['testes_sucesso']}")
    print(f"üìä Taxa de sucesso: {resumo['taxa_sucesso']:.1f}%")
    print(f"üéØ Status geral: {resumo['status_geral'].upper()}")
    
    print("\n‚úÖ Teste completo finalizado!")
    return resultados

if __name__ == "__main__":
    resultados = main()
